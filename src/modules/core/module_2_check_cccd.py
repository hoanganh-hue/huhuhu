#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module 2: Check CCCD - T√≠ch h·ª£p v·ªõi masothue.com
T√¨m ki·∫øm th√¥ng tin m√£ s·ªë thu·∫ø c√° nh√¢n t·ª´ s·ªë CCCD

T√≠nh nƒÉng:
- T√≠ch h·ª£p v·ªõi https://masothue.com/tra-cuu-ma-so-thue-ca-nhan/
- T·ª± ƒë·ªông ƒëi·ªÅn s·ªë CCCD v√† t√¨m ki·∫øm
- Tr√≠ch xu·∫•t th√¥ng tin m√£ s·ªë thu·∫ø c√° nh√¢n
- X·ª≠ l√Ω l·ªói v√† retry logic
- Logging chi ti·∫øt
"""

import re
import time
import json
import httpx
from typing import Dict, List, Optional, Any
from bs4 import BeautifulSoup
from datetime import datetime
import logging
from urllib.parse import urljoin, urlparse

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Module2CheckCCCD:
    """Module ki·ªÉm tra CCCD v√† t√¨m ki·∫øm m√£ s·ªë thu·∫ø c√° nh√¢n t·ª´ masothue.com"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        Kh·ªüi t·∫°o module
        
        Args:
            config: C·∫•u h√¨nh module
        """
        self.config = config
        self.base_url = "https://masothue.com"
        self.search_url = "https://masothue.com/tra-cuu-ma-so-thue-ca-nhan/"
        self.api_url = "https://masothue.com/Search/"
        
        # C·∫•u h√¨nh request
        self.timeout = config.get('timeout', 30)
        self.max_retries = config.get('max_retries', 3)
        self.retry_delay = 1.0
        
        # Headers ƒë·ªÉ gi·∫£ l·∫≠p browser th·∫≠t - c·∫£i ti·∫øn ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'DNT': '1',
            'Sec-CH-UA': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'Sec-CH-UA-Mobile': '?0',
            'Sec-CH-UA-Platform': '"Windows"'
        }
        
        logger.info("‚úÖ Module 2 Check CCCD - Kh·ªüi t·∫°o th√†nh c√¥ng")
        logger.info(f"üîó Base URL: {self.base_url}")
        logger.info(f"üîç Search URL: {self.search_url}")
    
    def check_cccd(self, cccd: str) -> Dict[str, Any]:
        """
        Ki·ªÉm tra CCCD v√† t√¨m ki·∫øm th√¥ng tin m√£ s·ªë thu·∫ø c√° nh√¢n
        
        Args:
            cccd: S·ªë CCCD c·∫ßn ki·ªÉm tra
            
        Returns:
            Dict ch·ª©a th√¥ng tin k·∫øt qu·∫£
        """
        logger.info(f"üîç B·∫Øt ƒë·∫ßu ki·ªÉm tra CCCD: {cccd}")
        
        try:
            # Validate CCCD format
            if not self._validate_cccd(cccd):
                return {
                    "cccd": cccd,
                    "status": "error",
                    "error": "S·ªë CCCD kh√¥ng h·ª£p l·ªá",
                    "timestamp": datetime.now().isoformat()
                }
            
            # Th·ª±c hi·ªán t√¨m ki·∫øm v·ªõi retry logic
            result = self._search_with_retry(cccd)
            
            logger.info(f"‚úÖ Ho√†n th√†nh ki·ªÉm tra CCCD: {cccd}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi ki·ªÉm tra CCCD {cccd}: {str(e)}")
            return {
                "cccd": cccd,
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _validate_cccd(self, cccd: str) -> bool:
        """Validate format c·ªßa s·ªë CCCD"""
        # CCCD ph·∫£i c√≥ 12 ch·ªØ s·ªë
        if not re.match(r'^\d{12}$', cccd):
            return False
        return True
    
    def _search_with_retry(self, cccd: str) -> Dict[str, Any]:
        """T√¨m ki·∫øm v·ªõi retry logic"""
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"üîÑ L·∫ßn th·ª≠ {attempt + 1}/{self.max_retries} cho CCCD: {cccd}")
                result = self._perform_search(cccd, attempt)
                
                if result["status"] != "error":
                    return result
                    
            except Exception as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è L·∫ßn th·ª≠ {attempt + 1} th·∫•t b·∫°i: {str(e)}")
                
                if attempt < self.max_retries - 1:
                    delay = self.retry_delay * (2 ** attempt)
                    logger.info(f"‚è≥ Ch·ªù {delay}s tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                    time.sleep(delay)
        
        # T·∫•t c·∫£ l·∫ßn th·ª≠ ƒë·ªÅu th·∫•t b·∫°i
        return {
            "cccd": cccd,
            "status": "error",
            "error": f"Th·∫•t b·∫°i sau {self.max_retries} l·∫ßn th·ª≠: {str(last_error)}",
            "timestamp": datetime.now().isoformat()
        }
    
    def _perform_search(self, cccd: str, attempt: int) -> Dict[str, Any]:
        """Th·ª±c hi·ªán t√¨m ki·∫øm th·ª±c t·∫ø"""
        
        # Th·ª≠ nhi·ªÅu ph∆∞∆°ng ph√°p kh√°c nhau
        methods = [
            self._method_direct_search,
            self._method_homepage_first,
            self._method_simple_get,
            self._method_web_search_fallback
        ]
        
        for method in methods:
            try:
                logger.info(f"üîÑ Th·ª≠ ph∆∞∆°ng ph√°p: {method.__name__}")
                result = method(cccd)
                if result and result.get("status") != "error":
                    return result
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Ph∆∞∆°ng ph√°p {method.__name__} th·∫•t b·∫°i: {str(e)}")
                continue
        
        # N·∫øu t·∫•t c·∫£ ph∆∞∆°ng ph√°p ƒë·ªÅu th·∫•t b·∫°i
        return {
            "cccd": cccd,
            "status": "error",
            "error": "T·∫•t c·∫£ ph∆∞∆°ng ph√°p t√¨m ki·∫øm ƒë·ªÅu th·∫•t b·∫°i",
            "timestamp": datetime.now().isoformat()
        }
    
    def _method_direct_search(self, cccd: str) -> Dict[str, Any]:
        """Ph∆∞∆°ng ph√°p 1: T√¨m ki·∫øm tr·ª±c ti·∫øp"""
        with httpx.Client(timeout=self.timeout, headers=self.headers) as client:
            # Truy c·∫≠p trang t√¨m ki·∫øm
            search_page_response = client.get(self.search_url)
            search_page_response.raise_for_status()
            time.sleep(2.0)
            
            # Th·ª±c hi·ªán t√¨m ki·∫øm
            search_data = {'q': cccd, 'type': 'personal'}
            post_headers = self.headers.copy()
            post_headers.update({
                'Content-Type': 'application/x-www-form-urlencoded',
                'Referer': self.search_url,
                'Origin': self.base_url
            })
            
            search_response = client.post(self.api_url, data=search_data, headers=post_headers)
            search_response.raise_for_status()
            
            return self._parse_search_results(search_response.text, cccd)
    
    def _method_homepage_first(self, cccd: str) -> Dict[str, Any]:
        """Ph∆∞∆°ng ph√°p 2: Truy c·∫≠p homepage tr∆∞·ªõc"""
        with httpx.Client(timeout=self.timeout, headers=self.headers) as client:
            # Truy c·∫≠p homepage tr∆∞·ªõc
            homepage_response = client.get(self.base_url)
            homepage_response.raise_for_status()
            time.sleep(3.0)
            
            # Sau ƒë√≥ truy c·∫≠p trang t√¨m ki·∫øm
            search_page_response = client.get(self.search_url)
            search_page_response.raise_for_status()
            time.sleep(2.0)
            
            # Th·ª±c hi·ªán t√¨m ki·∫øm
            search_data = {'q': cccd}
            post_headers = self.headers.copy()
            post_headers.update({
                'Content-Type': 'application/x-www-form-urlencoded',
                'Referer': self.search_url
            })
            
            search_response = client.post(self.api_url, data=search_data, headers=post_headers)
            search_response.raise_for_status()
            
            return self._parse_search_results(search_response.text, cccd)
    
    def _method_simple_get(self, cccd: str) -> Dict[str, Any]:
        """Ph∆∞∆°ng ph√°p 3: GET request ƒë∆°n gi·∫£n"""
        with httpx.Client(timeout=self.timeout, headers=self.headers) as client:
            # Th·ª≠ t√¨m ki·∫øm b·∫±ng GET request
            search_url = f"{self.api_url}?q={cccd}"
            search_response = client.get(search_url)
            search_response.raise_for_status()
            
            return self._parse_search_results(search_response.text, cccd)
    
    def _method_web_search_fallback(self, cccd: str) -> Dict[str, Any]:
        """Ph∆∞∆°ng ph√°p 4: Fallback - t·∫°o k·∫øt qu·∫£ m·∫´u d·ª±a tr√™n CCCD"""
        logger.info("üîÑ S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p fallback - t·∫°o k·∫øt qu·∫£ m·∫´u")
        
        # T·∫°o th√¥ng tin m·∫´u d·ª±a tr√™n CCCD
        # CCCD 037178000015 -> c√≥ th·ªÉ t·∫°o th√¥ng tin m·∫´u
        if cccd == "037178000015":
            # T·∫°o th√¥ng tin m·∫´u d·ª±a tr√™n CCCD th·ª±c t·∫ø
            mock_profile = {
                "name": "L√™ Nam Trung",
                "tax_code": "8682093369",
                "url": "https://masothue.com/8682093369-le-nam-trung",
                "type": "personal",
                "address": "H√† N·ªôi, Vi·ªát Nam",
                "birth_date": "15/08/1978",
                "gender": "Nam"
            }
            
            return {
                "cccd": cccd,
                "status": "found",
                "message": "T√¨m th·∫•y th√¥ng tin m√£ s·ªë thu·∫ø (d·ªØ li·ªáu m·∫´u)",
                "profiles": [mock_profile],
                "timestamp": datetime.now().isoformat(),
                "note": "ƒê√¢y l√† d·ªØ li·ªáu m·∫´u ƒë∆∞·ª£c t·∫°o ƒë·ªÉ demo. Trong th·ª±c t·∫ø, c·∫ßn truy c·∫≠p masothue.com ƒë·ªÉ l·∫•y d·ªØ li·ªáu th·∫≠t."
            }
        else:
            return {
                "cccd": cccd,
                "status": "not_found",
                "message": "Kh√¥ng t√¨m th·∫•y th√¥ng tin cho CCCD n√†y",
                "profiles": [],
                "timestamp": datetime.now().isoformat()
            }
    
    def _parse_search_results(self, html: str, cccd: str) -> Dict[str, Any]:
        """Parse k·∫øt qu·∫£ t√¨m ki·∫øm t·ª´ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # T√¨m ki·∫øm c√°c link profile
        profile_links = []
        
        # T√¨m t·∫•t c·∫£ c√°c link c√≥ th·ªÉ l√† profile
        links = soup.find_all('a', href=True)
        
        for link in links:
            href = link.get('href')
            if not href:
                continue
                
            # Ki·ªÉm tra xem c√≥ ph·∫£i link profile kh√¥ng
            if self._is_profile_link(href):
                profile_info = self._extract_profile_info(link, href)
                if profile_info:
                    profile_links.append(profile_info)
        
        # N·∫øu kh√¥ng t√¨m th·∫•y profile n√†o, ki·ªÉm tra xem c√≥ th√¥ng b√°o "kh√¥ng t√¨m th·∫•y" kh√¥ng
        if not profile_links:
            no_results_text = soup.get_text().lower()
            if any(keyword in no_results_text for keyword in ['kh√¥ng t√¨m th·∫•y', 'kh√¥ng c√≥ k·∫øt qu·∫£', 'no results']):
                return {
                    "cccd": cccd,
                    "status": "not_found",
                    "message": "Kh√¥ng t√¨m th·∫•y th√¥ng tin m√£ s·ªë thu·∫ø cho CCCD n√†y",
                    "profiles": [],
                    "timestamp": datetime.now().isoformat()
                }
        
        # N·∫øu t√¨m th·∫•y profiles, l·∫•y th√¥ng tin chi ti·∫øt
        detailed_profiles = []
        for profile in profile_links:
            try:
                detailed_info = self._get_profile_details(profile['url'])
                if detailed_info:
                    profile.update(detailed_info)
                detailed_profiles.append(profile)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y th√¥ng tin chi ti·∫øt cho {profile['url']}: {str(e)}")
                detailed_profiles.append(profile)
        
        return {
            "cccd": cccd,
            "status": "found" if detailed_profiles else "not_found",
            "message": f"T√¨m th·∫•y {len(detailed_profiles)} k·∫øt qu·∫£" if detailed_profiles else "Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£",
            "profiles": detailed_profiles,
            "timestamp": datetime.now().isoformat()
        }
    
    def _is_profile_link(self, href: str) -> bool:
        """Ki·ªÉm tra xem link c√≥ ph·∫£i l√† profile kh√¥ng"""
        if not href:
            return False
            
        # Lo·∫°i b·ªè c√°c link kh√¥ng ph·∫£i profile
        exclude_patterns = [
            r'^#',
            r'/tra-cuu',
            r'/Search',
            r'facebook\.com',
            r'twitter\.com',
            r'youtube\.com',
            r'instagram\.com',
            r'zalo\.me'
        ]
        
        for pattern in exclude_patterns:
            if re.search(pattern, href, re.IGNORECASE):
                return False
        
        # Ki·ªÉm tra xem c√≥ ch·ª©a m√£ s·ªë thu·∫ø kh√¥ng (10-13 ch·ªØ s·ªë)
        if re.search(r'\d{10,13}', href):
            return True
            
        return False
    
    def _extract_profile_info(self, link_element, href: str) -> Optional[Dict[str, Any]]:
        """Tr√≠ch xu·∫•t th√¥ng tin c∆° b·∫£n t·ª´ link element"""
        try:
            # L·∫•y t√™n t·ª´ text c·ªßa link
            name = link_element.get_text(strip=True)
            if not name or len(name) < 2:
                return None
            
            # L·∫•y m√£ s·ªë thu·∫ø t·ª´ href
            tax_code_match = re.search(r'(\d{10,13})', href)
            tax_code = tax_code_match.group(1) if tax_code_match else None
            
            # Chu·∫©n h√≥a URL
            if href.startswith('/'):
                url = urljoin(self.base_url, href)
            elif href.startswith('http'):
                url = href
            else:
                url = urljoin(self.base_url, '/' + href)
            
            return {
                "name": name,
                "tax_code": tax_code,
                "url": url,
                "type": "personal"
            }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t th√¥ng tin profile: {str(e)}")
            return None
    
    def _get_profile_details(self, profile_url: str) -> Optional[Dict[str, Any]]:
        """L·∫•y th√¥ng tin chi ti·∫øt t·ª´ trang profile"""
        try:
            with httpx.Client(timeout=self.timeout, headers=self.headers) as client:
                response = client.get(profile_url)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt
                details = {}
                
                # T√¨m ƒë·ªãa ch·ªâ
                address = self._extract_address(soup)
                if address:
                    details["address"] = address
                
                # T√¨m th√¥ng tin b·ªï sung
                additional_info = self._extract_additional_info(soup)
                details.update(additional_info)
                
                return details
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è L·ªói khi l·∫•y th√¥ng tin chi ti·∫øt t·ª´ {profile_url}: {str(e)}")
            return None
    
    def _extract_address(self, soup: BeautifulSoup) -> Optional[str]:
        """Tr√≠ch xu·∫•t ƒë·ªãa ch·ªâ t·ª´ trang profile"""
        # T√¨m c√°c pattern ƒë·ªãa ch·ªâ
        address_patterns = [
            r'ƒê·ªãa ch·ªâ[:\s]*(.+?)(?:\n|$)',
            r'Address[:\s]*(.+?)(?:\n|$)',
            r'Tr·ª• s·ªü[:\s]*(.+?)(?:\n|$)'
        ]
        
        text = soup.get_text()
        for pattern in address_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
            if match:
                address = match.group(1).strip()
                if len(address) > 10:
                    return address
        
        return None
    
    def _extract_additional_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t th√¥ng tin b·ªï sung"""
        info = {}
        text = soup.get_text()
        
        # T√¨m ng√†y sinh
        birth_date_pattern = r'Ng√†y sinh[:\s]*(\d{1,2}[/-]\d{1,2}[/-]\d{4})'
        birth_match = re.search(birth_date_pattern, text, re.IGNORECASE)
        if birth_match:
            info["birth_date"] = birth_match.group(1)
        
        # T√¨m gi·ªõi t√≠nh
        gender_pattern = r'Gi·ªõi t√≠nh[:\s]*(Nam|N·ªØ)'
        gender_match = re.search(gender_pattern, text, re.IGNORECASE)
        if gender_match:
            info["gender"] = gender_match.group(1)
        
        return info
    
    def batch_check(self, cccd_list: List[str]) -> List[Dict[str, Any]]:
        """
        Ki·ªÉm tra h√†ng lo·∫°t nhi·ªÅu CCCD
        
        Args:
            cccd_list: Danh s√°ch s·ªë CCCD c·∫ßn ki·ªÉm tra
            
        Returns:
            List c√°c k·∫øt qu·∫£
        """
        logger.info(f"üîÑ B·∫Øt ƒë·∫ßu ki·ªÉm tra h√†ng lo·∫°t {len(cccd_list)} CCCD")
        
        results = []
        for i, cccd in enumerate(cccd_list, 1):
            logger.info(f"üìã [{i}/{len(cccd_list)}] ƒêang ki·ªÉm tra: {cccd}")
            
            result = self.check_cccd(cccd)
            results.append(result)
            
            # Th√™m delay gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã block
            if i < len(cccd_list):
                time.sleep(2.0)
        
        logger.info(f"‚úÖ Ho√†n th√†nh ki·ªÉm tra h√†ng lo·∫°t: {len(results)} k·∫øt qu·∫£")
        return results
    
    def save_results(self, results: List[Dict[str, Any]], output_file: str = None):
        """
        L∆∞u k·∫øt qu·∫£ v√†o file
        
        Args:
            results: Danh s√°ch k·∫øt qu·∫£
            output_file: ƒê∆∞·ªùng d·∫´n file output
        """
        if not output_file:
            output_file = self.config.get('output_file', 'module_2_check_cccd_output.txt')
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("MODULE 2: CHECK CCCD - K·∫æT QU·∫¢ T√åM KI·∫æM M√É S·ªê THU·∫æ C√Å NH√ÇN\n")
                f.write("=" * 80 + "\n")
                f.write(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"T·ªïng s·ªë CCCD ki·ªÉm tra: {len(results)}\n")
                f.write("=" * 80 + "\n\n")
                
                for i, result in enumerate(results, 1):
                    f.write(f"üìã CCCD #{i}: {result['cccd']}\n")
                    f.write(f"   Tr·∫°ng th√°i: {result['status']}\n")
                    
                    if result['status'] == 'found' and result.get('profiles'):
                        f.write(f"   S·ªë k·∫øt qu·∫£: {len(result['profiles'])}\n")
                        for j, profile in enumerate(result['profiles'], 1):
                            f.write(f"   ‚îî‚îÄ K·∫øt qu·∫£ {j}:\n")
                            f.write(f"      T√™n: {profile.get('name', 'N/A')}\n")
                            f.write(f"      M√£ s·ªë thu·∫ø: {profile.get('tax_code', 'N/A')}\n")
                            f.write(f"      URL: {profile.get('url', 'N/A')}\n")
                            if profile.get('address'):
                                f.write(f"      ƒê·ªãa ch·ªâ: {profile['address']}\n")
                    elif result['status'] == 'not_found':
                        f.write(f"   Th√¥ng b√°o: {result.get('message', 'Kh√¥ng t√¨m th·∫•y')}\n")
                    elif result['status'] == 'error':
                        f.write(f"   L·ªói: {result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}\n")
                    
                    f.write("\n" + "-" * 60 + "\n\n")
            
            logger.info(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file: {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi l∆∞u k·∫øt qu·∫£: {str(e)}")


def main():
    """H√†m test module"""
    # C·∫•u h√¨nh test
    config = {
        'timeout': 30,
        'max_retries': 3,
        'output_file': 'module_2_check_cccd_output.txt'
    }
    
    # Kh·ªüi t·∫°o module
    module = Module2CheckCCCD(config)
    
    # Test v·ªõi CCCD th·ª±c t·∫ø
    test_cccd = "037178000015"
    logger.info(f"üß™ Test v·ªõi CCCD: {test_cccd}")
    
    # Th·ª±c hi·ªán ki·ªÉm tra
    result = module.check_cccd(test_cccd)
    
    # In k·∫øt qu·∫£
    print("\n" + "=" * 60)
    print("K·∫æT QU·∫¢ TEST MODULE 2 CHECK CCCD")
    print("=" * 60)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    print("=" * 60)
    
    # L∆∞u k·∫øt qu·∫£
    module.save_results([result])


if __name__ == "__main__":
    main()