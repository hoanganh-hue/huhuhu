#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module 2 Enhanced: Check CCCD - T√≠ch h·ª£p v·ªõi masothue.com v·ªõi kh·∫£ nƒÉng ch·ªëng bot
T√¨m ki·∫øm th√¥ng tin m√£ s·ªë thu·∫ø c√° nh√¢n t·ª´ s·ªë CCCD v·ªõi proxy v√† anti-bot

T√≠nh nƒÉng:
- T√≠ch h·ª£p v·ªõi https://masothue.com/tra-cuu-ma-so-thue-ca-nhan/
- H·ªó tr·ª£ SOCKS5 v√† HTTP proxy
- Anti-bot protection v·ªõi browser simulation
- Tr√≠ch xu·∫•t th√¥ng tin th·ª±c t·∫ø t·ª´ HTML
- X·ª≠ l√Ω Brotli compression
- Logging chi ti·∫øt
"""

import re
import time
import json
import requests
import logging
from typing import Dict, List, Optional, Any
from bs4 import BeautifulSoup
from datetime import datetime
from dataclasses import dataclass, field
import os
import random

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """K·∫øt qu·∫£ t√¨m ki·∫øm CCCD"""
    cccd: str
    status: str
    tax_code: Optional[str] = None
    name: Optional[str] = None
    full_name: Optional[str] = None
    address: Optional[str] = None
    business_type: Optional[str] = None
    business_status: Optional[str] = None
    registration_date: Optional[str] = None
    profile_url: Optional[str] = None
    error: Optional[str] = None
    method: Optional[str] = None
    response_time: Optional[float] = None
    additional_info: Dict[str, Any] = field(default_factory=dict)

class Module2CheckCCCDEnhanced:
    """Module ki·ªÉm tra CCCD n√¢ng cao v·ªõi kh·∫£ nƒÉng ch·ªëng bot v√† proxy"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        Kh·ªüi t·∫°o module
        
        Args:
            config: C·∫•u h√¨nh module
        """
        self.config = config
        self.base_url = "https://masothue.com"
        self.search_url = "https://masothue.com/Search/"
        
        # C·∫•u h√¨nh request
        self.timeout = config.get('timeout', 30)
        self.max_retries = config.get('max_retries', 3)
        self.retry_delay = 1.0
        
        # Proxy configuration
        self.proxy_config = self._load_proxy_config()
        
        # Browser-like headers
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Language": "vi,en-US;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0"
        }
        
        # Statistics
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "proxy_rotations": 0
        }
        
        logger.info("‚úÖ Module 2 Check CCCD Enhanced - Kh·ªüi t·∫°o th√†nh c√¥ng")
        logger.info(f"üîó Base URL: {self.base_url}")
        logger.info(f"üåê Proxy enabled: {self.proxy_config.get('enabled', False)}")
        if self.proxy_config.get('enabled', False):
            logger.info(f"üîó Proxy type: {self.proxy_config.get('type', 'none')}")
            if self.proxy_config.get('type') == 'socks5':
                socks5_config = self.proxy_config.get('socks5', {})
                logger.info(f"üåê SOCKS5: {socks5_config.get('host', 'N/A')}:{socks5_config.get('port', 'N/A')}")
    
    def _load_proxy_config(self) -> Dict[str, Any]:
        """Load proxy configuration from config object, environment or config file"""
        proxy_config = {
            'enabled': False,
            'type': 'socks5',
            'socks5': {'host': '', 'port': '', 'username': '', 'password': ''},
            'http': {'host': '', 'port': '', 'username': '', 'password': ''}
        }
        
        try:
            # First, try to load from config object (passed during initialization)
            if self.config.get('proxy_enabled'):
                proxy_config['enabled'] = True
                proxy_config['type'] = self.config.get('proxy_type', 'socks5')
                
                if proxy_config['type'] == 'socks5':
                    proxy_config['socks5']['host'] = self.config.get('proxy_socks5_host', '')
                    proxy_config['socks5']['port'] = self.config.get('proxy_socks5_port', '')
                    proxy_config['socks5']['username'] = self.config.get('proxy_socks5_username', '')
                    proxy_config['socks5']['password'] = self.config.get('proxy_socks5_password', '')
                elif proxy_config['type'] == 'http':
                    proxy_config['http']['host'] = self.config.get('proxy_http_host', '')
                    proxy_config['http']['port'] = self.config.get('proxy_http_port', '')
                    proxy_config['http']['username'] = self.config.get('proxy_http_username', '')
                    proxy_config['http']['password'] = self.config.get('proxy_http_password', '')
            
            # If not found in config object, try to load from config file
            elif os.path.exists('config/proxy_config.json'):
                with open('config/proxy_config.json', 'r', encoding='utf-8') as f:
                    file_config = json.load(f)
                    proxy_config.update(file_config)
            
            # Finally, override with environment variables
            if os.getenv('PROXY_ENABLED', '').lower() == 'true':
                proxy_config['enabled'] = True
                proxy_config['type'] = os.getenv('PROXY_TYPE', 'socks5')
                
                # SOCKS5 config
                proxy_config['socks5']['host'] = os.getenv('PROXY_SOCKS5_HOST', '')
                proxy_config['socks5']['port'] = os.getenv('PROXY_SOCKS5_PORT', '')
                proxy_config['socks5']['username'] = os.getenv('PROXY_SOCKS5_USERNAME', '')
                proxy_config['socks5']['password'] = os.getenv('PROXY_SOCKS5_PASSWORD', '')
                
                # HTTP config
                proxy_config['http']['host'] = os.getenv('PROXY_HTTP_HOST', '')
                proxy_config['http']['port'] = os.getenv('PROXY_HTTP_PORT', '')
                proxy_config['http']['username'] = os.getenv('PROXY_HTTP_USERNAME', '')
                proxy_config['http']['password'] = os.getenv('PROXY_HTTP_PASSWORD', '')
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load proxy config: {e}")
        
        return proxy_config
    
    def _get_session(self) -> requests.Session:
        """T·∫°o session v·ªõi proxy configuration"""
        session = requests.Session()
        session.headers.update(self.headers)
        
        if self.proxy_config.get('enabled', False):
            proxy_type = self.proxy_config.get('type', 'socks5')
            
            if proxy_type == 'socks5':
                proxy_info = self.proxy_config['socks5']
                if proxy_info['host'] and proxy_info['port']:
                    if proxy_info['username'] and proxy_info['password']:
                        proxy_url = f"socks5://{proxy_info['username']}:{proxy_info['password']}@{proxy_info['host']}:{proxy_info['port']}"
                    else:
                        proxy_url = f"socks5://{proxy_info['host']}:{proxy_info['port']}"
                    
                    session.proxies = {"http": proxy_url, "https": proxy_url}
                    logger.info(f"üåê SOCKS5 Proxy: {proxy_info['host']}:{proxy_info['port']}")
            
            elif proxy_type == 'http':
                proxy_info = self.proxy_config['http']
                if proxy_info['host'] and proxy_info['port']:
                    if proxy_info['username'] and proxy_info['password']:
                        proxy_url = f"http://{proxy_info['username']}:{proxy_info['password']}@{proxy_info['host']}:{proxy_info['port']}"
                    else:
                        proxy_url = f"http://{proxy_info['host']}:{proxy_info['port']}"
                    
                    session.proxies = {"http": proxy_url, "https": proxy_url}
                    logger.info(f"üåê HTTP Proxy: {proxy_info['host']}:{proxy_info['port']}")
        
        return session
    
    def _random_delay(self, min_delay: float = 2.0, max_delay: float = 5.0):
        """Random delay ƒë·ªÉ tr√°nh b·ªã ph√°t hi·ªán"""
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
    
    def _get_homepage_cookies(self, session: requests.Session) -> bool:
        """L·∫•y cookies t·ª´ homepage"""
        try:
            logger.info("üç™ Getting cookies from homepage...")
            response = session.get("https://masothue.com/", timeout=15)
            response.raise_for_status()
            logger.info(f"‚úÖ Cookies collected: {len(response.cookies)} cookies")
            return True
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Failed to get homepage cookies: {e}")
            return False
    
    def check_cccd(self, cccd: str) -> SearchResult:
        """
        Ki·ªÉm tra CCCD v√† t√¨m ki·∫øm th√¥ng tin m√£ s·ªë thu·∫ø c√° nh√¢n
        
        Args:
            cccd: S·ªë CCCD c·∫ßn ki·ªÉm tra
            
        Returns:
            SearchResult ch·ª©a th√¥ng tin k·∫øt qu·∫£
        """
        logger.info(f"üîç Starting enhanced search for CCCD: {cccd}")
        
        self.stats["total_requests"] += 1
        
        try:
            # Validate CCCD format
            if not self._validate_cccd(cccd):
                return SearchResult(
                    cccd=cccd,
                    status="error",
                    error="S·ªë CCCD kh√¥ng h·ª£p l·ªá"
                )
            
            # Th·ª±c hi·ªán t√¨m ki·∫øm v·ªõi retry logic
            result = self._search_with_retry(cccd)
            
            if result.status == "found":
                self.stats["successful_requests"] += 1
            else:
                self.stats["failed_requests"] += 1
            
            logger.info(f"‚úÖ Completed search for CCCD: {cccd} - Status: {result.status}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error checking CCCD {cccd}: {str(e)}")
            self.stats["failed_requests"] += 1
            return SearchResult(
                cccd=cccd,
                status="error",
                error=str(e)
            )
    
    def _validate_cccd(self, cccd: str) -> bool:
        """Validate format c·ªßa s·ªë CCCD"""
        # CCCD ph·∫£i c√≥ 12 ch·ªØ s·ªë
        if not re.match(r'^\d{12}$', cccd):
            return False
        return True
    
    def _search_with_retry(self, cccd: str) -> SearchResult:
        """T√¨m ki·∫øm v·ªõi retry logic"""
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"üîÑ Attempt {attempt + 1}/{self.max_retries} for CCCD: {cccd}")
                
                # T·∫°o session m·ªõi cho m·ªói l·∫ßn th·ª≠
                session = self._get_session()
                
                # L·∫•y cookies t·ª´ homepage
                self._get_homepage_cookies(session)
                
                # Th·ª±c hi·ªán t√¨m ki·∫øm
                result = self._perform_search(session, cccd)
                
                if result.status != "error":
                    return result
                    
            except Exception as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è Attempt {attempt + 1} failed: {str(e)}")
                
                if attempt < self.max_retries - 1:
                    delay = self.retry_delay * (2 ** attempt)
                    logger.info(f"‚è≥ Waiting {delay}s before retry...")
                    time.sleep(delay)
        
        # T·∫•t c·∫£ l·∫ßn th·ª≠ ƒë·ªÅu th·∫•t b·∫°i
        return SearchResult(
            cccd=cccd,
            status="error",
            error=f"Failed after {self.max_retries} attempts: {str(last_error)}"
        )
    
    def _perform_search(self, session: requests.Session, cccd: str) -> SearchResult:
        """Th·ª±c hi·ªán t√¨m ki·∫øm th·ª±c t·∫ø"""
        start_time = time.time()
        
        try:
            # Random delay
            self._random_delay(1.0, 3.0)
            
            # Search parameters
            params = {
                "q": cccd,
                "type": "auto",
                "token": "NbnmgilFfL",
                "force-search": "1",
            }
            
            # Add search-specific headers
            search_headers = self.headers.copy()
            search_headers.update({
                "Referer": "https://masothue.com/",
                "X-Requested-With": "XMLHttpRequest"
            })
            
            logger.info(f"üîç Searching for CCCD: {cccd}")
            response = session.get(self.search_url, params=params, headers=search_headers, timeout=15)
            response.raise_for_status()
            
            end_time = time.time()
            response_time = end_time - start_time
            
            logger.info(f"‚úÖ Request successful: {response.status_code}")
            logger.info(f"‚è±Ô∏è Response time: {response_time:.2f}s")
            logger.info(f"üìä Content length: {len(response.content)} bytes")
            
            # Parse HTML to extract data
            result = self._parse_masothue_response(response.text, cccd)
            result.response_time = response_time
            result.method = "enhanced_requests"
            
            return result
            
        except requests.exceptions.RequestException as e:
            end_time = time.time()
            logger.error(f"‚ùå Request failed: {e}")
            return SearchResult(
                cccd=cccd,
                status="error",
                error=str(e),
                response_time=end_time - start_time
            )
    
    def _parse_masothue_response(self, html_content: str, cccd: str) -> SearchResult:
        """Parse k·∫øt qu·∫£ t·ª´ masothue.com"""
        logger.info("üìÑ Parsing HTML content...")
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Extract all text content
        all_text = soup.get_text()
        logger.info(f"üìÑ Total text content length: {len(all_text)} characters")
        
        # Initialize result
        result = SearchResult(cccd=cccd, status="not_found")
        
        # Method 1: Look for tax code and name in links
        all_links = soup.find_all('a', href=True)
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)
            
            # Check for tax code profile links
            if '/masothue.com/' in href and href != 'https://masothue.com/':
                # Extract tax code from URL
                url_parts = href.split('/')
                if len(url_parts) > 0:
                    last_part = url_parts[-1]
                    if '-' in last_part:
                        potential_tax_code = last_part.split('-')[0]
                        if potential_tax_code.isdigit() and len(potential_tax_code) == 10:
                            result.tax_code = potential_tax_code
                            result.name = text
                            result.profile_url = href
                            result.status = "found"
                            logger.info(f"üéØ Found tax code: {potential_tax_code}")
                            logger.info(f"üë§ Found name: {text}")
                            logger.info(f"üîó Profile URL: {href}")
                            break
        
        # Method 2: Look for tax code in text content
        if not result.tax_code:
            tax_pattern = r'\b\d{10}\b'
            matches = re.findall(tax_pattern, all_text)
            if matches:
                result.tax_code = matches[0]
                logger.info(f"üéØ Found tax code in text: {matches[0]}")
        
        # Method 3: Look for Vietnamese names
        if not result.name:
            # Vietnamese name patterns
            vietnamese_patterns = [
                r'[A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê][a-z√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë\s]+',
                r'[A-Z][a-z]+\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*'
            ]
            
            for pattern in vietnamese_patterns:
                matches = re.findall(pattern, all_text)
                for match in matches:
                    match = match.strip()
                    if len(match) > 5 and len(match) < 50:
                        # Check if it looks like a Vietnamese name
                        if any(char in match for char in ['L√™', 'Nguy·ªÖn', 'Tr·∫ßn', 'Ph·∫°m', 'Ho√†ng', 'Phan', 'V≈©', 'V√µ', 'ƒê·ªó', 'B√πi', 'ƒê·∫∑ng', 'Ng√¥', 'D∆∞∆°ng', 'L√Ω']):
                            result.name = match
                            result.status = "found"
                            logger.info(f"üë§ Found Vietnamese name: {match}")
                            break
                if result.name:
                    break
        
        # Method 4: Look for address information
        address_keywords = ['ph∆∞·ªùng', 'qu·∫≠n', 'huy·ªán', 't·ªânh', 'th√†nh ph·ªë', 'x√£', 'th·ªã tr·∫•n', 'ƒë∆∞·ªùng', 'ph·ªë']
        address_elements = soup.find_all(['p', 'div', 'span', 'td'])
        
        for elem in address_elements:
            text = elem.get_text(strip=True)
            if text and len(text) > 20:
                if any(keyword in text.lower() for keyword in address_keywords):
                    result.address = text
                    logger.info(f"üè† Found address: {text}")
                    break
        
        # Method 5: Look for business information
        business_keywords = ['c√¥ng ty', 'doanh nghi·ªáp', 't·ªï ch·ª©c', 'c√° nh√¢n', 'h·ªô kinh doanh']
        for elem in soup.find_all(['p', 'div', 'span', 'td']):
            text = elem.get_text(strip=True)
            if text and any(keyword in text.lower() for keyword in business_keywords):
                result.business_type = text
                logger.info(f"üè¢ Found business type: {text}")
                break
        
        # Method 6: Look for status information
        status_keywords = ['ho·∫°t ƒë·ªông', 'ng·ª´ng ho·∫°t ƒë·ªông', 'ƒëang ho·∫°t ƒë·ªông', 't·∫°m ngh·ªâ']
        for elem in soup.find_all(['p', 'div', 'span', 'td']):
            text = elem.get_text(strip=True)
            if text and any(keyword in text.lower() for keyword in status_keywords):
                result.business_status = text
                logger.info(f"üìä Found business status: {text}")
                break
        
        # Method 7: Look for dates
        date_pattern = r'\d{1,2}[/-]\d{1,2}[/-]\d{4}|\d{4}[/-]\d{1,2}[/-]\d{1,2}'
        date_matches = re.findall(date_pattern, all_text)
        if date_matches:
            result.registration_date = date_matches[0]
            logger.info(f"üìÖ Found date: {date_matches[0]}")
        
        # Method 8: Extract additional structured data
        tables = soup.find_all('table')
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    key = cells[0].get_text(strip=True)
                    value = cells[1].get_text(strip=True)
                    if key and value:
                        result.additional_info[key] = value
        
        # Method 9: Look for specific data in divs with classes
        data_divs = soup.find_all('div', class_=re.compile(r'info|data|detail|profile'))
        for div in data_divs:
            text = div.get_text(strip=True)
            if text and len(text) > 5:
                result.additional_info[f"div_content_{len(result.additional_info)}"] = text
        
        logger.info(f"üìä Extracted {len(result.additional_info)} additional data fields")
        
        return result
    
    def batch_check(self, cccd_list: List[str]) -> List[SearchResult]:
        """
        Ki·ªÉm tra h√†ng lo·∫°t nhi·ªÅu CCCD
        
        Args:
            cccd_list: Danh s√°ch s·ªë CCCD c·∫ßn ki·ªÉm tra
            
        Returns:
            List c√°c k·∫øt qu·∫£
        """
        logger.info(f"üîÑ Starting batch check for {len(cccd_list)} CCCDs")
        
        results = []
        for i, cccd in enumerate(cccd_list, 1):
            logger.info(f"üìã [{i}/{len(cccd_list)}] Checking: {cccd}")
            
            result = self.check_cccd(cccd)
            results.append(result)
            
            # Th√™m delay gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã block
            if i < len(cccd_list):
                self._random_delay(3.0, 7.0)
        
        logger.info(f"‚úÖ Completed batch check: {len(results)} results")
        return results
    
    def save_results(self, results: List[SearchResult], output_file: str = None):
        """
        L∆∞u k·∫øt qu·∫£ v√†o file
        
        Args:
            results: Danh s√°ch k·∫øt qu·∫£
            output_file: ƒê∆∞·ªùng d·∫´n file output
        """
        if not output_file:
            output_file = self.config.get('output_file', 'module_2_check_cccd_enhanced_output.txt')
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("MODULE 2 ENHANCED: CHECK CCCD - K·∫æT QU·∫¢ T√åM KI·∫æM M√É S·ªê THU·∫æ C√Å NH√ÇN\n")
                f.write("=" * 80 + "\n")
                f.write(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"T·ªïng s·ªë CCCD ki·ªÉm tra: {len(results)}\n")
                f.write(f"Proxy enabled: {self.proxy_config.get('enabled', False)}\n")
                f.write(f"Proxy type: {self.proxy_config.get('type', 'none')}\n")
                f.write("=" * 80 + "\n\n")
                
                for i, result in enumerate(results, 1):
                    f.write(f"üìã CCCD #{i}: {result.cccd}\n")
                    f.write(f"   Tr·∫°ng th√°i: {result.status}\n")
                    f.write(f"   Ph∆∞∆°ng ph√°p: {result.method or 'N/A'}\n")
                    f.write(f"   Th·ªùi gian ph·∫£n h·ªìi: {result.response_time:.2f}s\n")
                    
                    if result.status == 'found':
                        if result.tax_code:
                            f.write(f"   M√£ s·ªë thu·∫ø: {result.tax_code}\n")
                        if result.name:
                            f.write(f"   T√™n: {result.name}\n")
                        if result.address:
                            f.write(f"   ƒê·ªãa ch·ªâ: {result.address}\n")
                        if result.business_type:
                            f.write(f"   Lo·∫°i h√¨nh: {result.business_type}\n")
                        if result.business_status:
                            f.write(f"   Tr·∫°ng th√°i: {result.business_status}\n")
                        if result.registration_date:
                            f.write(f"   Ng√†y ƒëƒÉng k√Ω: {result.registration_date}\n")
                        if result.profile_url:
                            f.write(f"   URL: {result.profile_url}\n")
                        
                        if result.additional_info:
                            f.write(f"   Th√¥ng tin b·ªï sung:\n")
                            for key, value in result.additional_info.items():
                                f.write(f"     {key}: {value}\n")
                    
                    elif result.status == 'not_found':
                        f.write(f"   Th√¥ng b√°o: Kh√¥ng t√¨m th·∫•y th√¥ng tin\n")
                    elif result.status == 'error':
                        f.write(f"   L·ªói: {result.error}\n")
                    
                    f.write("\n" + "-" * 60 + "\n\n")
            
            logger.info(f"üíæ Saved results to file: {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Error saving results: {str(e)}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ ho·∫°t ƒë·ªông"""
        return {
            "total_requests": self.stats["total_requests"],
            "successful_requests": self.stats["successful_requests"],
            "failed_requests": self.stats["failed_requests"],
            "success_rate": (self.stats["successful_requests"] / max(1, self.stats["total_requests"])) * 100,
            "proxy_enabled": self.proxy_config.get('enabled', False),
            "proxy_type": self.proxy_config.get('type', 'none')
        }


def main():
    """H√†m test module"""
    # C·∫•u h√¨nh test
    config = {
        'timeout': 30,
        'max_retries': 3,
        'output_file': 'module_2_check_cccd_enhanced_output.txt'
    }
    
    # Kh·ªüi t·∫°o module
    module = Module2CheckCCCDEnhanced(config)
    
    # Test v·ªõi CCCD th·ª±c t·∫ø
    test_cccd = "031089011929"
    logger.info(f"üß™ Testing with CCCD: {test_cccd}")
    
    # Th·ª±c hi·ªán ki·ªÉm tra
    result = module.check_cccd(test_cccd)
    
    # In k·∫øt qu·∫£
    print("\n" + "=" * 60)
    print("K·∫æT QU·∫¢ TEST MODULE 2 CHECK CCCD ENHANCED")
    print("=" * 60)
    print(f"CCCD: {result.cccd}")
    print(f"Status: {result.status}")
    print(f"Tax Code: {result.tax_code}")
    print(f"Name: {result.name}")
    print(f"Address: {result.address}")
    print(f"Business Type: {result.business_type}")
    print(f"Profile URL: {result.profile_url}")
    print(f"Response Time: {result.response_time:.2f}s")
    print(f"Method: {result.method}")
    if result.error:
        print(f"Error: {result.error}")
    print("=" * 60)
    
    # L∆∞u k·∫øt qu·∫£
    module.save_results([result])
    
    # In th·ªëng k√™
    stats = module.get_statistics()
    print("\nüìä TH·ªêNG K√ä:")
    print(f"Total requests: {stats['total_requests']}")
    print(f"Successful: {stats['successful_requests']}")
    print(f"Failed: {stats['failed_requests']}")
    print(f"Success rate: {stats['success_rate']:.1f}%")
    print(f"Proxy enabled: {stats['proxy_enabled']}")


if __name__ == "__main__":
    main()